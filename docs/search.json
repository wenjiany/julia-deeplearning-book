[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Julia for Deep Learning",
    "section": "",
    "text": "Preface\nThis book provides an overview of a pure Julia implementation of the fastai book: Deep Learning for Coders with fastai and PyTorch. The original book works with Python and PyTorch. This book works with Julia and relies primarily on Flux.jl (Innes 2018). The original book is written by Jeremy Howard and Sylvain Gugge (Howard and Gugger 2020). This book is written by participants of the Julia for Deep Learning course.\nThe book is served from GitHub.\n\n\n\n\nHoward, Jeremy, and Sylvain Gugger. 2020. Deep Learning for Coders with Fastai and PyTorch. \"O’Reilly Media, Inc.\".\n\n\nInnes, Mike. 2018. “Flux: Elegant Machine Learning with Julia.” Journal of Open Source Software 3 (25): 602."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "chapters/c4.html#computing-metrics-using-broadcasting",
    "href": "chapters/c4.html#computing-metrics-using-broadcasting",
    "title": "2  Chapter 4: Under the Hood: Training a Digit Classifier",
    "section": "2.1 Computing Metrics Using Broadcasting",
    "text": "2.1 Computing Metrics Using Broadcasting\nThe rule of broadcasting in Julia is different from Python? In Python, first align all dimensions to the right, then broadcast. In Julia, first align all dimensions to the left, then broadcast. So in python [1000, 28, 28] - [28, 28] is allowed, but in Julia, we need [28, 28, 1000] - [28, 28]. Use permutedims to change the order of dimensions.\n\nvalid_threes = sort(readdir(joinpath(data_path, \"test\", \"3\")))\nvalid_3_tens = MLUtils.stack([load(joinpath(data_path, \"test\", \"3\", img)) for img in valid_threes])\n\nvalid_sevens = sort(readdir(joinpath(data_path, \"test\", \"7\")))\nvalid_7_tens = MLUtils.stack([load(joinpath(data_path, \"test\", \"7\", img)) for img in valid_sevens])\n\n# valid_3_tens = permutedims(valid_3_tens, [3, 1, 2])\n\nsize(valid_3_tens), size(valid_7_tens)\n\n((28, 28, 1010), (28, 28, 1028))\n\n\n\nfunction mnist_distance(a, b)\n    mm = mean(Float32.(abs.(a .- b)), dims=(1, 2))\n    return dropdims(mm, dims=(1, 2))\nend\n\nmnist_distance(a_3, mean3)[1]\n\n0.12612005f0\n\n\n\nvalid_3_dist = mnist_distance(valid_3_tens, mean3)\n(size(valid_3_dist), valid_3_dist)\n\n((1010,), Float32[0.12803426, 0.16230617, 0.12421783, 0.14686641, 0.120200165, 0.118782386, 0.16995831, 0.12664512, 0.13367367, 0.11829293  …  0.12947088, 0.1525875, 0.1556588, 0.13255748, 0.13654083, 0.17447978, 0.12789737, 0.15078008, 0.12630658, 0.12596397])\n\n\n\nsize(valid_3_tens .- mean3)\n\n(28, 28, 1010)\n\n\n\nis_3(x) = mnist_distance(x, mean3) .&lt; mnist_distance(x, mean7)\n\nis_3 (generic function with 1 method)\n\n\n\nis_3(a_3)\nis_3(valid_3_tens[:, :, 1:10])\n\nis_3(valid_7_tens[:, :, 1:10])\n\n10-element BitVector:\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n 0\n\n\n\naccuracy_3s = mean(is_3(valid_3_tens))\naccuracy_7s = mean(1 .- is_3(valid_7_tens))\n\naccuracy_3s, accuracy_7s\n\n(0.9168316831683169, 0.9854085603112841)"
  },
  {
    "objectID": "chapters/c4.html#calculating-gradients",
    "href": "chapters/c4.html#calculating-gradients",
    "title": "2  Chapter 4: Under the Hood: Training a Digit Classifier",
    "section": "2.2 Calculating Gradients",
    "text": "2.2 Calculating Gradients\n\n2.2.1 Using Flux.jl\nTaking gradients in Flux.jl is as simple as calling gradient on a function. For example, to take the gradient of f(x) = x^2 at x = 2, we can do the following:\n\nf(x) = x^2\ndf(x) = gradient(f, x)[1]\ndf(2)\n\n4.0\n\n\nBelow we implement and visualise gradient descent from scratch in Julia.\n\nxmax = 10\nn = 100\nplt = plot(\n    range(-xmax, xmax, length=n), f;\n    label=\"f(x)\", lw=5, xlim=1.5 .* [-xmax, xmax],\n    xlab=\"Parameter\", ylab=\"Loss\", legend=false\n)\n\nnsteps = 10\nlrs = [0.05, 0.3, 0.975, 1.025]\ndescend(x; lr=0.1) = x - lr * df(x)\nx = [-0.75xmax]\nx = repeat(x, length(lrs), 1)                             # repeat x for each learning rate\nplts = [deepcopy(plt) for i in 1:length(lrs)]           # repeat plt for each learning rate\nanim = @animate for j in 1:nsteps\n    global x = hcat(x, zeros(size(x, 1)))                # add column of zeros to x\n    for (i, lr) in enumerate(lrs)\n        _plt = plot(plts[i], title=\"lr = $lr\", ylims=(0, f(xmax)), legend=false)\n        scatter!([x[i, j]], [f(x[i, j])]; label=nothing, ms=5, c=:red)    # plot current point\n        x[i, j+1] = descend(x[i, j]; lr=lr)                               # descend\n        Δx = x[i, j+1] - x[i, j]\n        Δy = f(x[i, j+1]) - f(x[i, j])\n        quiver!([x[i, j]], [f(x[i, j])], quiver=([Δx], [0]), c=:red)          # horizontal arrow\n        quiver!([x[i, j+1]], [f(x[i, j])], quiver=([0], [Δy]), c=:red)        # vertical arrow\n        plts[i] = _plt\n    end\n    plot(\n        plts..., legend=false,\n        plot_title=\"Step $j\", margin=5mm,\n        dpi=300,\n    )\nend\ngif(anim, joinpath(www_path, \"c4_gd.gif\"), fps=0.5)\n\n\n\n\nFigure 2.1: Gradient descent for different learning rates"
  },
  {
    "objectID": "chapters/c4.html#an-end-to-end-sgd-example",
    "href": "chapters/c4.html#an-end-to-end-sgd-example",
    "title": "2  Chapter 4: Under the Hood: Training a Digit Classifier",
    "section": "2.3 An End-to-End SGD Example",
    "text": "2.3 An End-to-End SGD Example\n\n## is time a good variable name?\ntime = collect(range(start=0, stop=19))\n\nspeed = @. $rand(20) + 0.75 * (time - 9.5)^2 + 1\n\nscatter(time, speed, legend=false, xlabel=\"time\", ylabel=\"speed\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction f(t, params)\n    a, b, c = params\n    return @. a * (t - b)^2 + c\nend\n\nfunction mse(preds, targets)\n    return sum((preds .- targets) .^ 2) / length(preds)\nend\n\nmse (generic function with 1 method)\n\n\n\nfunction show_preds(preds)\n    scatter(time, speed)\n    scatter!(time, preds, color=\"red\")\nend\n\nshow_preds (generic function with 1 method)\n\n\n\nparams = rand(3)\npreds = f(time, params)\n\nshow_preds(preds)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloss = mse(preds, speed)\n\n8296.82143644548\n\n\n\ndloss(params) = gradient(params -&gt; mse(f(time, params), speed), params)\n\ngrad = dloss(params)[1]\n\nlr = 1e-5\nparams = params .- lr .* grad\n\npreds = f(time, params)\nmse(preds, speed)\n\nshow_preds(preds)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## params will be updated in place\nfunction apply_step!(params; lr=1e-5, prn=true)\n    grad = dloss(params)[1]\n    params .-= lr * grad ## inplace update\n    preds = f(time, params)\n    loss = mse(preds, speed)\n    if prn\n        println(loss)\n        println(grad)\n        println(params)\n    end\n    return preds\nend\n\napply_step! (generic function with 1 method)\n\n\n\nparams = rand(3)\nplts = []\n\nfor i in range(1, 4)\n    push!(plts, show_preds(apply_step!(params; lr=0.0001, prn=false)))\nend\n\nplot(\n    plts..., legend=false,\n    plot_title=\"First four steps\", margin=5mm,\n    dpi=300,\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\nparams = rand(3)\npreds = f(time, params)\n\nplts = []\npush!(plts, show_preds(preds))\n\nlr = 0.0001  ## how to adjust learning rate? takes a lot of time to learn\nfor i in range(0, 60000)\n    apply_step!(params, prn=false)\nend\n\npreds = apply_step!(params, prn=true);\npush!(plts, show_preds(preds))\n\nplot(\n    plts..., legend=false,\n    plot_title=\"After 60000 steps\", margin=5mm,\n    dpi=300,\n)\n\n10.90886132109632\n[-0.0735022149927751, -0.0003901579811111944, 4.383430999602089]\n[0.6672579211758306, 9.493901611682551, 6.352134871734056]"
  },
  {
    "objectID": "chapters/c4.html#the-mnist-loss-function",
    "href": "chapters/c4.html#the-mnist-loss-function",
    "title": "2  Chapter 4: Under the Hood: Training a Digit Classifier",
    "section": "2.4 The MNIST Loss Function",
    "text": "2.4 The MNIST Loss Function\n\ntrain_x = cat(stacked_threes, stacked_sevens, dims=3) |&gt; x -&gt; reshape(x, 28 * 28, :) |&gt; transpose;\ntrain_y = vcat(repeat([1], size(stacked_threes)[3]), repeat([0], size(stacked_sevens)[3]));\n\nsize(train_x), size(train_y)\n\n((12396, 784), (12396,))\n\n\n\ndset = [(train_x[i, :], train_y[i]) for i in range(1, size(train_x)[1])]\nx, y = dset[1]\nsize(dset), size(x), y\n\n((12396,), (784,), 1)\n\n\n\nvalid_x = cat(valid_3_tens, valid_7_tens, dims=3) |&gt; x -&gt; reshape(x, 28 * 28, :) |&gt; transpose;\nvalid_y = vcat(repeat([1], size(valid_3_tens)[3]), repeat([0], size(valid_7_tens)[3]));\nvalid_dset = zip(eachrow(valid_x), valid_y);\n\nsize(valid_x), size(valid_y), size(valid_dset)\n\n((2038, 784), (2038,), (2038,))\n\n\n\ninit_params(size; std=1.0) = randn(size) * std\n\nweights = init_params((28 * 28, 1))\n\nbias = init_params(1)\n\nsize(weights), size(bias)\n\n((784, 1), (1,))\n\n\n\ntrain_x = convert(Array{Float32}, train_x)\n\ntrain_x[1:1, :] * weights .+ bias\n\n1×1 Matrix{Float64}:\n -3.501327342352872\n\n\nPytorch tensor provides a tag to indicate if gradient is to be computed. This is not needed in Flux? To get gradient, just use gradient function in Flux\n\ngradient(weights -&gt; sum(train_x[1:1, :] * weights), weights)\n\n([0.0; 0.0; … ; 0.0; 0.0;;],)\n\n\n\nlinear1(xb) = xb * weights .+ bias\npreds = linear1(train_x)\n\n12396×1 Matrix{Float64}:\n  -3.501327342352871\n  -7.803989646297762\n   0.6762347534331052\n  -3.023752660788845\n  -9.516878292448476\n  -7.033978158406221\n  -4.121724962898755\n   7.818492504419868\n  -2.4782311140758995\n   3.779727107749914\n  -3.408244480726173\n  -7.060928958728613\n  -2.1788888600992573\n   ⋮\n   9.819611612539923\n   0.8538666355803137\n   2.3249911800591567\n  -3.8884379846078874\n  -4.1295855377706445\n  -0.14468002821284043\n   1.5411110361966878\n  -6.228736530914673\n  -2.1027676354594456\n -11.00265384543037\n  -0.504937167730418\n   4.139620206286243\n\n\n\ncorrects = (preds .&gt; 0.0) .=== Bool.(train_y)\n\nmean(corrects)\n\n0.6069699903194579\n\n\n\nweights[1] *= 1.0001\n\npreds = linear1(train_x)\nmean((preds .&gt; 0.0) .== Bool.(train_y))\n\n0.6069699903194579\n\n\n\ntrgts = [1, 0, 1]\nprds = [0.9, 0.4, 0.2]\n\nmnist_loss(predictions, targets) = mean(t === 1 ? 1 - p : p for (p, t) in zip(predictions, targets))\n\nmnist_loss(prds, trgts), mnist_loss([0.9, 0.4, 0.8], trgts)\n\n(0.43333333333333335, 0.2333333333333333)\n\n\n\nsigmoid(x) = 1 / (1 + exp(-x))\n\nprint(sigmoid.(rand(10)))\n\nplot(range(-5, 5, length=100), sigmoid)\n\n[0.6410273776045075, 0.6105076166250384, 0.5783704340117538, 0.6426148235103056, 0.6852254892841372, 0.5984580626393032, 0.6717542924899141, 0.517005739780998, 0.5656790579343766, 0.6485622582089181]\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction mnist_loss(predictions, targets)\n    predictions = sigmoid.(predictions)\n    return mean([t === 1 ? 1 - p : p for (p, t) in zip(predictions, targets)])\nend\n\nmnist_loss (generic function with 1 method)"
  },
  {
    "objectID": "chapters/c4.html#sgd-and-mini-batches",
    "href": "chapters/c4.html#sgd-and-mini-batches",
    "title": "2  Chapter 4: Under the Hood: Training a Digit Classifier",
    "section": "2.5 SGD and Mini-Batches",
    "text": "2.5 SGD and Mini-Batches\n\ncoll = range(1, 15)\n\ndl = DataLoader((coll), batchsize=5, shuffle=true)\n\ncollect(dl)\n\n3-element Vector{Vector{Int64}}:\n [2, 4, 8, 1, 10]\n [12, 14, 7, 15, 3]\n [6, 9, 11, 5, 13]\n\n\n\nlowercase_alphabets = 'a':'z' ## [Char(i) for i in 97:122]\n\nds = [ (i, v) for (i, v) in enumerate(lowercase_alphabets)]\n\ndl = DataLoader(ds, batchsize=5, shuffle=true)\ncollect(dl)\n\n6-element Vector{Vector{Tuple{Int64, Char}}}:\n [(13, 'm'), (24, 'x'), (2, 'b'), (4, 'd'), (26, 'z')]\n [(20, 't'), (25, 'y'), (12, 'l'), (22, 'v'), (18, 'r')]\n [(15, 'o'), (7, 'g'), (5, 'e'), (3, 'c'), (11, 'k')]\n [(23, 'w'), (16, 'p'), (1, 'a'), (6, 'f'), (21, 'u')]\n [(14, 'n'), (8, 'h'), (9, 'i'), (19, 's'), (10, 'j')]\n [(17, 'q')]\n\n\nDoes dataloader work with files and directories?\n\nweights = init_params((28*28,1))\nbias = init_params(1)\nsize(weights), size(bias)\n\n((784, 1), (1,))\n\n\n\nfunction reformat_dl(d1) \n    xb = MLUtils.stack([x for (x, y) in d1], dims=1)\n    yb = MLUtils.stack([[y] for (x, y) in d1], dims=1)\n    return xb, yb\nend\n\ndl = DataLoader(dset, batchsize=256, shuffle=true)\n\nd1 = first(dl)\nlength(d1)\n\nxb, yb = reformat_dl(d1)\n\nsize(xb), size(yb)\n\n((256, 784), (256, 1))\n\n\n\nvalid_x = convert(Array{Float32}, valid_x)\n\nvalid_dset = [(valid_x[i, :], valid_y[i]) for i in range(1, size(valid_x)[1])]\n\nvalid_dl = DataLoader(valid_dset, batchsize=256, shuffle=true)\n\n8-element DataLoader(::Vector{Tuple{Vector{Float32}, Int64}}, shuffle=true, batchsize=256)\n  with first element:\n  256-element Vector{Tuple{Vector{Float32}, Int64}}\n\n\n\nbatch = train_x[1:4, :]\nsize(batch)\n\npreds = linear1(batch)\n\nloss = mnist_loss(preds, train_y[1:4])\n\n## redefine linear layer to include weights and bias as parameters\n\nlinear1(xb, weights, bias) = xb * weights .+ bias\npreds = linear1(batch, weights, bias)\n\ncurr_gr = gradient(weights, bias) do weights, bias\n    preds = linear1(batch, weights, bias)\n    mnist_loss(preds, train_y[1:4])\nend\n\n([0.0; 0.0; … ; 0.0; 0.0;;], [-0.00019200529295718371])\n\n\n\n# using dictionary to store parameters\n\nparams = Dict(\"weights\" =&gt; weights, \"bias\" =&gt; bias)\n\nlinear1(xb, params) = xb * params[\"weights\"] .+ params[\"bias\"]\n\ncurr_gr = gradient(params) do params\n    preds = linear1(batch, params)\n    mnist_loss(preds, train_y[1:4])\nend\n\n(Dict{Any, Any}(\"weights\" =&gt; [0.0; 0.0; … ; 0.0; 0.0;;], \"bias\" =&gt; [-0.00019200529295718371]),)\n\n\n\nlr = 1e-4\nfunction calc_grad(xb, yb, model, weights, bias)\n    preds = model(xb, weights, bias)\n    loss = mnist_loss(preds, yb)\n    curr_gr = gradient(weights, bias) do weights, bias\n        preds = model(xb, weights, bias)\n        mnist_loss(preds, yb)\n    end\nend\n\ncalc_grad (generic function with 1 method)\n\n\nUsing params dictionary.\n\nfunction calc_grad(xb, yb, model, params)\n    preds = model(xb, params)\n    loss = mnist_loss(preds, yb)\n    curr_gr = gradient(params) do params\n        preds = model(xb, params)\n        mnist_loss(preds, yb)\n    end\nend\n\ncalc_grad (generic function with 2 methods)\n\n\n\ncurr_grad = calc_grad(batch, train_y[1:4], linear1, weights, bias)\ndict_grad = calc_grad(batch, train_y[1:4], linear1, params)[1]\n## weights.grad.mean(),bias.grad\n\nmean(curr_grad[1]), mean(curr_grad[2])\nmean(dict_grad[\"weights\"]), mean(dict_grad[\"bias\"])\n\n(-3.7275223954992516e-5, -0.00019200529295718371)\n\n\n\nfunction train_epoch(model, lr, params)\n    for dd in dl\n        xb, yb = reformat_dl(dd)\n        grad = calc_grad(xb, yb, model, params)[1]\n        for k in keys(params)\n            params[k] .-= grad[k] * lr\n            ## no need to zero_grad? in Pytorch, p.grad.zero_()\n        end\n    end\nend\n\ntrain_epoch(linear1, lr, params)\n\n\n(preds .&gt; 0.0) == Bool.(train_y[1:4])\n\nfalse\n\n\n\nfunction batch_accuracy(xb, yb)\n    preds = sigmoid.(xb)\n    correct = (preds .&gt; 0.5) .== yb\n    return mean(correct)\nend\n\nbatch_accuracy(linear1(batch, params), train_y[1:4])\n\n1.0\n\n\n\nfunction validate_epoch(model)\n    accs = zeros(length(valid_dl))\n    i = 1\n    for dd in valid_dl\n        xb, yb = reformat_dl(dd)\n        accs[i] = batch_accuracy(model(xb, params), yb)\n        i = i + 1\n    end\n    return round(mean(accs), digits=4)\nend\n\nfunction train_accuracy(model)\n    accs = zeros(length(dl))\n    i = 1\n    for dd in dl\n        xb, yb = reformat_dl(dd)\n        accs[i] = batch_accuracy(model(xb, params), yb)\n        i = i + 1\n    end\n    return round(mean(accs), digits=4)\nend\n\ntrain_accuracy (generic function with 1 method)\n\n\n\nlr = 1\n\nweights = init_params((28 * 28, 1))\nbias = init_params(1)\n\nparams = Dict(\"weights\" =&gt; weights, \"bias\" =&gt; bias)\n\ntrain_epoch(linear1, lr, params)\n\nvalidate_epoch(linear1)\n\n0.9275\n\n\n\nfor i in range(1, 20)\n    train_epoch(linear1, lr, params)\n    println((i, validate_epoch(linear1), train_accuracy(linear1)))\nend\n\n(1, 0.9499, 0.9512)\n(2, 0.9583, 0.9591)\n(3, 0.9612, 0.9639)\n(4, 0.9632, 0.9657)\n(5, 0.9638, 0.9678)\n(6, 0.9656, 0.9694)\n(7, 0.9656, 0.9705)\n(8, 0.9681, 0.9716)\n(9, 0.9686, 0.9722)\n(10, 0.9706, 0.9731)\n(11, 0.9711, 0.9737)\n(12, 0.973, 0.9745)\n(13, 0.9735, 0.9756)\n(14, 0.9735, 0.9762)\n(15, 0.974, 0.9771)\n(16, 0.9741, 0.9774)\n(17, 0.9744, 0.9776)\n(18, 0.9749, 0.9789)\n(19, 0.9749, 0.9787)\n(20, 0.9749, 0.9794)"
  },
  {
    "objectID": "chapters/c4.html#creating-an-optimizer",
    "href": "chapters/c4.html#creating-an-optimizer",
    "title": "2  Chapter 4: Under the Hood: Training a Digit Classifier",
    "section": "2.6 Creating an Optimizer",
    "text": "2.6 Creating an Optimizer\nA Flux based implementation\n\nmodel = Chain(\n    Dense(28 * 28 =&gt; 1),\n    Flux.sigmoid  ## or σ\n)\n\noptim = Flux.setup(Flux.Adam(1.0), model)\n\nlosses = []\n\nfor epoch in 1:20\n    for dd in dl\n        xb, yb = reformat_dl(dd)\n        loss, grads = Flux.withgradient(model) do m\n            # Evaluate model and loss inside gradient context:\n            y_hat = m(xb')\n            Flux.binarycrossentropy(y_hat, yb')  # mnist_loss(y_hat', yb)\n        end\n        Flux.update!(optim, model, grads[1])\n        push!(losses, loss)  # logging, outside gradient context\n    end\nend\n\noptim # parameters, momenta and output have all changed\n\nxb, yb = reformat_dl(first(valid_dl))\n\nout2 = model(xb')  # first row is prob. of true, second row p(false)\n\nmean((out2[1, :] .&gt; 0.5) .== yb)\n\n0.9921875\n\n\nShow examples of predicting seven and three.\n\nxb, yb = reformat_dl(collect(valid_dl)[end])\n\nseven_examples = rand(findall(y -&gt; y == 0, yb[:]), 9)\n\nconvert(Array{Gray}, mosaic(map(i -&gt; reshape(xb[i, :], 28, 28), seven_examples), ncol=3))\n\n[b &gt; 0.5 ? \"three\" : \"seven\" for b in model(xb[seven_examples, :]')]\n\n1×9 Matrix{String}:\n \"three\"  \"seven\"  \"seven\"  \"seven\"  …  \"seven\"  \"seven\"  \"seven\"  \"seven\"\n\n\n\nthree_examples = rand(findall(y -&gt; y == 1, yb[:]), 9)\nconvert(Array{Gray}, mosaic(map(i -&gt; reshape(xb[i, :], 28, 28), three_examples), ncol=3))\n[b &gt; 0.5 ? \"three\" : \"seven\" for b in model(xb[three_examples, :]')]\n\n1×9 Matrix{String}:\n \"three\"  \"three\"  \"three\"  \"three\"  …  \"three\"  \"three\"  \"three\"  \"three\""
  },
  {
    "objectID": "chapters/c4.html#adding-a-nonlinearity",
    "href": "chapters/c4.html#adding-a-nonlinearity",
    "title": "2  Chapter 4: Under the Hood: Training a Digit Classifier",
    "section": "2.7 Adding a Nonlinearity",
    "text": "2.7 Adding a Nonlinearity\n\nfunction simple_net1(xb)\n    res = xb * w1 .+ b1'\n    res[res.&lt;0] .= 0\n    res = res * w2 .+ b2\n    return res\nend\n\nw1 = init_params((28 * 28, 30))\nb1 = init_params(30)\nw2 = init_params((30, 1))\nb2 = init_params(1)\n\nsimple_net1(train_x[1:4, :])\n\n4×1 Matrix{Float64}:\n -126.8325425611682\n  -91.884731723257\n -106.8205913364877\n -138.07959754797585\n\n\n\nplot(range(-5, 5), Flux.relu)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsimple_net_flux = Chain(\n    Flux.Dense(28 * 28, 30),\n    Flux.relu,\n    Flux.Dense(30, 1)\n)\n\nFlux.params(simple_net_flux[1])[1] .= w1'\nFlux.params(simple_net_flux[1])[2] .= b1\n\nFlux.params(simple_net_flux[3])[1] .= w2'\nFlux.params(simple_net_flux[3])[2] .= b2\n\nsimple_net_flux(train_x[1:4, :]')\n\n1×4 Matrix{Float32}:\n -126.833  -91.8847  -106.821  -138.08"
  },
  {
    "objectID": "chapters/c4.html#training-a-digit-classifier",
    "href": "chapters/c4.html#training-a-digit-classifier",
    "title": "2  Chapter 4: Under the Hood: Training a Digit Classifier",
    "section": "2.8 Training a Digit Classifier",
    "text": "2.8 Training a Digit Classifier\nThe MNIST dataset can be loaded in Julia as follows:\n\n# Data\nX, y = MLDatasets.MNIST(:train)[:]\ny_enc = Flux.onehotbatch(y, 0:9)\nXtest, ytest = MLDatasets.MNIST(:test)[:]\nytest_enc = onehotbatch(ytest, 0:9)\nmosaic(map(i -&gt; convert2image(MNIST, X[:, :, i]), rand(1:60000, 100)), ncol=10)\n\n\n\n\nWe can preprocess the data as follows:\n\ni_train, i_val = [], []\nfor (k, v) in group_indices(y)\n    _i_train, _i_val = splitobs(v, at=0.7)\n    push!(i_train, _i_train...)\n    push!(i_val, _i_val...)\nend\nXtrain, ytrain = X[:, :, i_train], y_enc[:, i_train]\nXval, yval = X[:, :, i_val], y_enc[:, i_val]\n\n([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 1 1; … ; 0 0 … 0 0; 0 0 … 0 0])\n\n\nNext, we define a data loader:\n\nbatchsize = 128\ntrain_set = DataLoader((Xtrain, ytrain), batchsize=batchsize, shuffle=true)\nval_set = DataLoader((Xval, yval), batchsize=batchsize)\n\n141-element DataLoader(::Tuple{Array{Float32, 3}, OneHotMatrix{UInt32, Vector{UInt32}}}, batchsize=128)\n  with first element:\n  (28×28×128 Array{Float32, 3}, 10×128 OneHotMatrix(::Vector{UInt32}) with eltype Bool,)\n\n\nWe can now define a model, based on how we preprocessed the data:\n\nmodel = Chain(\n    Flux.flatten,\n    Dense(28^2, 32, relu),\n    Dense(32, 10),\n    softmax\n)\n\n\nChain(\n  Flux.flatten,\n  Dense(784 =&gt; 32, relu),               # 25_120 parameters\n  Dense(32 =&gt; 10),                      # 330 parameters\n  NNlib.softmax,\n)                   # Total: 4 arrays, 25_450 parameters, 99.664 KiB.\n\n\n\nFinally, what’s left to do is to define a loss function and an optimiser:\n\nloss(y_hat, y) = Flux.Losses.crossentropy(y_hat, y)\nopt_state = Flux.setup(Adam(), model)\n\nBefore we start training, we define some helper functions:\n\n# Callbacks:\nfunction accuracy(model, data::DataLoader)\n    acc = 0\n    for (x, y) in data\n        acc += sum(onecold(model(x)) .== onecold(y)) / size(y, 2)\n    end\n    return acc / length(data)\nend\n\nfunction avg_loss(model, data::DataLoader)\n    _loss = 0\n    for (x, y) in data\n        _loss += loss(model(x), y)[1]\n    end\n    return _loss / length(data)\nend\n\nAs a very last step, we set up our training logs:\n\n# Final setup:\nnepochs = 100\nacc_train, acc_val = accuracy(model, train_set), accuracy(model, val_set)\nloss_train, loss_val = avg_loss(model, train_set), avg_loss(model, val_set)\n\nlog = DataFrame(\n    epoch=0,\n    acc_train=acc_train,\n    acc_val=acc_val,\n    loss_train=loss_train,\n    loss_val=loss_val\n)\n\nBelow we finally train our model:\n\n# Training loop:\nfor epoch in 1:nepochs\n\n    for (i, data) in enumerate(train_set)\n\n        # Extract data:\n        input, label = data\n\n        # Compute loss and gradient:\n        val, grads = Flux.withgradient(model) do m\n            result = m(input)\n            loss(result, label)\n        end\n\n        # Detect loss of Inf or NaN. Print a warning, and then skip update!\n        if !isfinite(val)\n            @warn \"loss is $val on item $i\" epoch\n            continue\n        end\n\n        Flux.update!(opt_state, model, grads[1])\n\n    end\n\n    # Monitor progress:\n    acc_train, acc_val = accuracy(model, train_set), accuracy(model, val_set)\n    loss_train, loss_val = avg_loss(model, train_set), avg_loss(model, val_set)\n    results = Dict(\n        :epoch =&gt; epoch,\n        :acc_train =&gt; acc_train,\n        :acc_val =&gt; acc_val,\n        :loss_train =&gt; loss_train,\n        :loss_val =&gt; loss_val\n    )\n    push!(log, results)\n\n    # Print progress:\n    vals = Matrix(results_df[2:end,[:loss_train,:loss_val]])\n    plt = UnicodePlots.lineplot(1:epoch, vals; \n        name=[\"Train\",\"Validation\"], title=\"Loss in epoch $epoch\", xlim=(1,nepochs))\n    UnicodePlots.display(plt)\n\nend\n\nFigure 2.2 shows the training and validation loss and accuracy over epochs. The model is overfitting, as the validation loss increases after bottoming out at around epoch 20.\n\noutput = DataFrame(log)\noutput = output[2:end, :]\n\nanim = @animate for epoch in 1:maximum(output.epoch)\n    p_loss = plot(output[1:epoch, :epoch], Matrix(output[1:epoch, [:loss_train, :loss_val]]),\n        label=[\"Train\" \"Validation\"], title=\"Loss\", legend=:topleft)\n    p_acc = plot(output[1:epoch, :epoch], Matrix(output[1:epoch, [:acc_train, :acc_val]]),\n        label=[\"Train\" \"Validation\"], title=\"Accuracy\", legend=:topleft)\n    plot(p_loss, p_acc, layout=(1, 2), dpi=300, margin=5mm, size=(800, 400))\nend\ngif(anim, joinpath(www_path, \"c4_mnist.gif\"), fps=5)\n\n\n\n\nFigure 2.2: Training and validation loss and accuracy"
  },
  {
    "objectID": "chapters/c5.html#using-the-data-block-api",
    "href": "chapters/c5.html#using-the-data-block-api",
    "title": "3  Chapter 5: Image Classification",
    "section": "3.1 Using the Data Block API",
    "text": "3.1 Using the Data Block API\n\n\n\n\n\n\nFastAI.jl convention\n\n\n\nContrary to fast.ai, FastAI.jl separates the data loading and container generation from the data augmentation. From the documentation:\n\nIn FastAI.jl, the preprocessing or “encoding” is implemented through a learning task. Learning tasks contain any configuration and, beside data processing, have extensible functions for visualizations and model building. One advantage of this separation between loading and encoding is that the data container can easily be swapped out as long as it has observations suitable for the learning task (in this case a tuple of two images and a Boolean). It also makes it easy to export models and all the necessary configuration.\n\n\n\nFirst, we follow the standard procedure to split the data into training and validation sets:\n\ntrain_data, val_data = splitobs(data; at=0.8, shuffle=true)\n\n(ObsView(::MLUtils.MappedData{:auto, typeof(loadimageclass), ObsView{MLDatasets.FileDataset{typeof(identity), String}, Vector{Int64}}}, ::Vector{Int64})\n 5912 observations, ObsView(::MLUtils.MappedData{:auto, typeof(loadimageclass), ObsView{MLDatasets.FileDataset{typeof(identity), String}, Vector{Int64}}}, ::Vector{Int64})\n 1478 observations)\n\n\nNext, we define the data augmentation task separately as a BlockTask:\n\n_resize = 128\nblocks = (\n    Image{2}(),\n    Label{String}(unique(labels)),\n)\ntask = BlockTask(\n    blocks,\n    (   \n        ProjectiveTransforms(\n            (_resize, _resize), \n            sharestate=false,\n            buffered=false,\n        ),\n        ImagePreprocessing(buffered=false),\n        OneHot(),\n    )\n)\ndescribetask(task)\n\nSupervisedTask summary\nLearning task for the supervised task with input Image{2} and target Label{String}. Compatible with models that take in Bounded{2, FastVision.ImageTensor{2}} and output OneHotLabel{String}.\nEncoding a sample (encodesample(task, context, sample)) is done through the following encodings:\n\n\n\n\n\n\n\n\n\nEncoding\nName\nblocks.input\nblocks.target\n\n\n\n\n\n(input, target)\nImage{2}\nLabel{String}\n\n\nProjectiveTransforms\n\nBounded{2, Image{2}}\n\n\n\nImagePreprocessing\n\nBounded{2, FastVision.ImageTensor{2}}\n\n\n\nOneHot\n(x, y)\n\nOneHotLabel{String}\n\n\n\n\n\nWe can apply the augmentation to the data as follows:\n\nbatchsize = 3\ntrain_dl, val_dl = taskdataloaders(train_data, val_data, task, batchsize)\n\n(DataLoader(::FastAI.TaskDataset{ObsView{MLUtils.MappedData{:auto, typeof(loadimageclass), ObsView{MLDatasets.FileDataset{typeof(identity), String}, Vector{Int64}}}, Vector{Int64}}, SupervisedTask{NamedTuple{(:input, :target, :sample, :encodedsample, :x, :y, :ŷ, :pred), Tuple{Image{2}, Label{String}, Tuple{Image{2}, Label{String}}, Tuple{Bounded{2, FastVision.ImageTensor{2}}, FastAI.OneHotTensor{0, String}}, Bounded{2, FastVision.ImageTensor{2}}, FastAI.OneHotTensor{0, String}, FastAI.OneHotTensor{0, String}, Label{String}}}, Tuple{ProjectiveTransforms{2, NamedTuple{(:training, :validation, :inference), Tuple{DataAugmentation.Sequence{Tuple{DataAugmentation.CroppedProjectiveTransform{DataAugmentation.ScaleKeepAspect{2}, DataAugmentation.Crop{2, DataAugmentation.FromRandom}}, DataAugmentation.PinOrigin}}, DataAugmentation.Sequence{Tuple{DataAugmentation.CroppedProjectiveTransform{DataAugmentation.ScaleKeepAspect{2}, DataAugmentation.Crop{2, DataAugmentation.FromCenter}}, DataAugmentation.PinOrigin}}, DataAugmentation.Sequence{Tuple{DataAugmentation.CroppedProjectiveTransform{DataAugmentation.ScaleKeepAspect{2}, DataAugmentation.PadDivisible}, DataAugmentation.PinOrigin}}}}}, ImagePreprocessing{N0f8, 3, RGB{N0f8}, Float32}, OneHot{DataType}}}, Training}, parallel=true, shuffle=true, batchsize=3, collate=Val{true}()), DataLoader(::FastAI.TaskDataset{ObsView{MLUtils.MappedData{:auto, typeof(loadimageclass), ObsView{MLDatasets.FileDataset{typeof(identity), String}, Vector{Int64}}}, Vector{Int64}}, SupervisedTask{NamedTuple{(:input, :target, :sample, :encodedsample, :x, :y, :ŷ, :pred), Tuple{Image{2}, Label{String}, Tuple{Image{2}, Label{String}}, Tuple{Bounded{2, FastVision.ImageTensor{2}}, FastAI.OneHotTensor{0, String}}, Bounded{2, FastVision.ImageTensor{2}}, FastAI.OneHotTensor{0, String}, FastAI.OneHotTensor{0, String}, Label{String}}}, Tuple{ProjectiveTransforms{2, NamedTuple{(:training, :validation, :inference), Tuple{DataAugmentation.Sequence{Tuple{DataAugmentation.CroppedProjectiveTransform{DataAugmentation.ScaleKeepAspect{2}, DataAugmentation.Crop{2, DataAugmentation.FromRandom}}, DataAugmentation.PinOrigin}}, DataAugmentation.Sequence{Tuple{DataAugmentation.CroppedProjectiveTransform{DataAugmentation.ScaleKeepAspect{2}, DataAugmentation.Crop{2, DataAugmentation.FromCenter}}, DataAugmentation.PinOrigin}}, DataAugmentation.Sequence{Tuple{DataAugmentation.CroppedProjectiveTransform{DataAugmentation.ScaleKeepAspect{2}, DataAugmentation.PadDivisible}, DataAugmentation.PinOrigin}}}}}, ImagePreprocessing{N0f8, 3, RGB{N0f8}, Float32}, OneHot{DataType}}}, Validation}, parallel=true, batchsize=6, collate=Val{true}()))\n\n\nLet’s quickly verify that the images look as expected:\n\nshowbatch(task, first(train_dl))\n\n\n\n\nFinally, we can build our model as follows. First, we define the backbone:\n\n# Get backbone:\n_backbone = Metalhead.ResNet(18, pretrain=true).layers[1][1:end-1]\n\n\nChain(\n  Chain(\n    Conv((7, 7), 3 =&gt; 64, pad=3, stride=2, bias=false),  # 9_408 parameters\n    BatchNorm(64, relu),                # 128 parameters, plus 128\n    MaxPool((3, 3), pad=1, stride=2),\n  ),\n  Chain(\n    Parallel(\n      addact(NNlib.relu, ...),\n      identity,\n      Chain(\n        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  # 36_864 parameters\n        BatchNorm(64),                  # 128 parameters, plus 128\n        NNlib.relu,\n        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  # 36_864 parameters\n        BatchNorm(64),                  # 128 parameters, plus 128\n      ),\n    ),\n    Parallel(\n      addact(NNlib.relu, ...),\n      identity,\n      Chain(\n        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  # 36_864 parameters\n        BatchNorm(64),                  # 128 parameters, plus 128\n        NNlib.relu,\n        Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  # 36_864 parameters\n        BatchNorm(64),                  # 128 parameters, plus 128\n      ),\n    ),\n  ),\n  Chain(\n    Parallel(\n      addact(NNlib.relu, ...),\n      Chain(\n        Conv((1, 1), 64 =&gt; 128, stride=2, bias=false),  # 8_192 parameters\n        BatchNorm(128),                 # 256 parameters, plus 256\n      ),\n      Chain(\n        Conv((3, 3), 64 =&gt; 128, pad=1, stride=2, bias=false),  # 73_728 parameters\n        BatchNorm(128),                 # 256 parameters, plus 256\n        NNlib.relu,\n        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  # 147_456 parameters\n        BatchNorm(128),                 # 256 parameters, plus 256\n      ),\n    ),\n    Parallel(\n      addact(NNlib.relu, ...),\n      identity,\n      Chain(\n        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  # 147_456 parameters\n        BatchNorm(128),                 # 256 parameters, plus 256\n        NNlib.relu,\n        Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  # 147_456 parameters\n        BatchNorm(128),                 # 256 parameters, plus 256\n      ),\n    ),\n  ),\n  Chain(\n    Parallel(\n      addact(NNlib.relu, ...),\n      Chain(\n        Conv((1, 1), 128 =&gt; 256, stride=2, bias=false),  # 32_768 parameters\n        BatchNorm(256),                 # 512 parameters, plus 512\n      ),\n      Chain(\n        Conv((3, 3), 128 =&gt; 256, pad=1, stride=2, bias=false),  # 294_912 parameters\n        BatchNorm(256),                 # 512 parameters, plus 512\n        NNlib.relu,\n        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  # 589_824 parameters\n        BatchNorm(256),                 # 512 parameters, plus 512\n      ),\n    ),\n    Parallel(\n      addact(NNlib.relu, ...),\n      identity,\n      Chain(\n        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  # 589_824 parameters\n        BatchNorm(256),                 # 512 parameters, plus 512\n        NNlib.relu,\n        Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  # 589_824 parameters\n        BatchNorm(256),                 # 512 parameters, plus 512\n      ),\n    ),\n  ),\n)         # Total: 45 trainable arrays, 2_782_784 parameters,\n          # plus 30 non-trainable, 4_480 parameters, summarysize 10.649 MiB.\n\n\n\nHere we have removed the final layer of the ResNet model, because we will instead use a custom head. We could use the taskmodel function to build the model with an appropriate head automatically:\n\nmodel = taskmodel(task, _backbone)\nmodel.layers[end]\n\n\nChain(\n  Parallel(vcat, AdaptiveMeanPool((1, 1)), AdaptiveMaxPool((1, 1))),\n  Flux.flatten,\n  Chain(\n    BatchNorm(512),                     # 1_024 parameters, plus 1_024\n    identity,\n    Dense(512 =&gt; 512, relu; bias=false),  # 262_144 parameters\n  ),\n  Chain(\n    BatchNorm(512),                     # 1_024 parameters, plus 1_024\n    identity,\n    Dense(512 =&gt; 37; bias=false),       # 18_944 parameters\n  ),\n)         # Total: 6 trainable arrays, 283_136 parameters,\n          # plus 4 non-trainable, 2_048 parameters, summarysize 1.089 MiB.\n\n\n\nEquivalently, we could have obtained an appropriate head as follows,\n\nh, w, ch, b = Flux.outputsize(_backbone, (_resize, _resize, 3, 1))\n_head = Models.visionhead(ch, length(unique(labels)))\n\n\nChain(\n  Parallel(vcat, AdaptiveMeanPool((1, 1)), AdaptiveMaxPool((1, 1))),\n  Flux.flatten,\n  Chain(\n    BatchNorm(512),                     # 1_024 parameters, plus 1_024\n    identity,\n    Dense(512 =&gt; 512, relu; bias=false),  # 262_144 parameters\n  ),\n  Chain(\n    BatchNorm(512),                     # 1_024 parameters, plus 1_024\n    identity,\n    Dense(512 =&gt; 37; bias=false),       # 18_944 parameters\n  ),\n)         # Total: 6 trainable arrays, 283_136 parameters,\n          # plus 4 non-trainable, 2_048 parameters, summarysize 1.089 MiB.\n\n\n\nand then construct our model by chaining the backbone and head:\n\nChain(_backbone, _head)\n\n\nChain(\n  Chain(\n    Chain(\n      Conv((7, 7), 3 =&gt; 64, pad=3, stride=2, bias=false),  # 9_408 parameters\n      BatchNorm(64, relu),              # 128 parameters, plus 128\n      MaxPool((3, 3), pad=1, stride=2),\n    ),\n    Chain(\n      Parallel(\n        addact(NNlib.relu, ...),\n        identity,\n        Chain(\n          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  # 36_864 parameters\n          BatchNorm(64),                # 128 parameters, plus 128\n          NNlib.relu,\n          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  # 36_864 parameters\n          BatchNorm(64),                # 128 parameters, plus 128\n        ),\n      ),\n      Parallel(\n        addact(NNlib.relu, ...),\n        identity,\n        Chain(\n          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  # 36_864 parameters\n          BatchNorm(64),                # 128 parameters, plus 128\n          NNlib.relu,\n          Conv((3, 3), 64 =&gt; 64, pad=1, bias=false),  # 36_864 parameters\n          BatchNorm(64),                # 128 parameters, plus 128\n        ),\n      ),\n    ),\n    Chain(\n      Parallel(\n        addact(NNlib.relu, ...),\n        Chain(\n          Conv((1, 1), 64 =&gt; 128, stride=2, bias=false),  # 8_192 parameters\n          BatchNorm(128),               # 256 parameters, plus 256\n        ),\n        Chain(\n          Conv((3, 3), 64 =&gt; 128, pad=1, stride=2, bias=false),  # 73_728 parameters\n          BatchNorm(128),               # 256 parameters, plus 256\n          NNlib.relu,\n          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  # 147_456 parameters\n          BatchNorm(128),               # 256 parameters, plus 256\n        ),\n      ),\n      Parallel(\n        addact(NNlib.relu, ...),\n        identity,\n        Chain(\n          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  # 147_456 parameters\n          BatchNorm(128),               # 256 parameters, plus 256\n          NNlib.relu,\n          Conv((3, 3), 128 =&gt; 128, pad=1, bias=false),  # 147_456 parameters\n          BatchNorm(128),               # 256 parameters, plus 256\n        ),\n      ),\n    ),\n    Chain(\n      Parallel(\n        addact(NNlib.relu, ...),\n        Chain(\n          Conv((1, 1), 128 =&gt; 256, stride=2, bias=false),  # 32_768 parameters\n          BatchNorm(256),               # 512 parameters, plus 512\n        ),\n        Chain(\n          Conv((3, 3), 128 =&gt; 256, pad=1, stride=2, bias=false),  # 294_912 parameters\n          BatchNorm(256),               # 512 parameters, plus 512\n          NNlib.relu,\n          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  # 589_824 parameters\n          BatchNorm(256),               # 512 parameters, plus 512\n        ),\n      ),\n      Parallel(\n        addact(NNlib.relu, ...),\n        identity,\n        Chain(\n          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  # 589_824 parameters\n          BatchNorm(256),               # 512 parameters, plus 512\n          NNlib.relu,\n          Conv((3, 3), 256 =&gt; 256, pad=1, bias=false),  # 589_824 parameters\n          BatchNorm(256),               # 512 parameters, plus 512\n        ),\n      ),\n    ),\n  ),\n  Chain(\n    Parallel(vcat, AdaptiveMeanPool((1, 1)), AdaptiveMaxPool((1, 1))),\n    Flux.flatten,\n    Chain(\n      BatchNorm(512),                   # 1_024 parameters, plus 1_024\n      identity,\n      Dense(512 =&gt; 512, relu; bias=false),  # 262_144 parameters\n    ),\n    Chain(\n      BatchNorm(512),                   # 1_024 parameters, plus 1_024\n      identity,\n      Dense(512 =&gt; 37; bias=false),     # 18_944 parameters\n    ),\n  ),\n)         # Total: 51 trainable arrays, 3_065_920 parameters,\n          # plus 34 non-trainable, 6_528 parameters, summarysize 11.740 MiB.\n\n\n\nWith the model defined, we can now create a Learner object from scratch:\n\n# Task data loader for new batch size:\nbatchsize = 64\ntrain_dl, val_dl = taskdataloaders(train_data, val_data, task, batchsize)\n\n# Set up loss function, optimizer, callbacks, and learner:\nlossfn = Flux.Losses.logitcrossentropy\noptimizer = Flux.Adam()\nerror_rate(ŷ, y) = mean(onecold(ŷ) .!= onecold(y)) \ncallbacks = [ToGPU(), Metrics(error_rate)]\n\nlearner = Learner(\n    model, (train_dl, val_dl),\n    optimizer, lossfn,\n    callbacks...\n)\n\nLearner()\n\n\n\n\n\n\n\n\nThe FastAI.jl way\n\n\n\nMost of the manual jobs above can be done automatically using the tasklearner function:\n\nlearner = tasklearner(\n    task, train_data, val_data; \n    backbone=_backbone, callbacks=callbacks,\n    lossfn=lossfn, optimizer=optimizer, batchsize=batchsize,\n)\n\nLearner()\n\n\nNote that in this case, we pass on the raw, non-encoded data to the tasklearner function. This is because the tasklearner function will automatically encode the data using the task object.\n\n\nWe will begin by using the learning rate finder to find a good learning rate:\n\nres = lrfind(learner)\n\n\n\n\nFigure 3.1: Learning rate finder output.\n\n\nBelow we fine-tune the model for 5 epochs and then save it to disk:\n\nfinetune!(learner, 5, 2e-3)\n\n\n\n\n\n\n\nFreeze epochs\n\n\n\nNote that by default, this will train the model for one epoch with pre-trained weights (our _backbone) completely frozen. In other weights, only the parameters of our _head will be updated during this epoch, before the second phase of training begins.\n\n\nNow we will fit the whole training cycle:\n\nfitonecycle!(learner, 5, 2e-3)\nsavetaskmodel(\"artifacts/c5_resnet.jld2\", task, learner.model, force=true)\n\nUsing our model, we can now make predictions on the validation set as follows:\n\ntask, model = loadtaskmodel(\"artifacts/c5_resnet.jld2\")\n\nsamples = [getobs(data, i) for i in rand(1:numobs(val_data), 3)]\nimages = [sample[1] for sample in samples]\n_labels = [sample[2] for sample in samples]\n\npreds = predictbatch(task, model, images; device = gpu, context=Validation())\n\n┌ Info: The GPU function is being called but the GPU is not accessible. \n└ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n\n\n3-element Vector{String}:\n \"bombay\"\n \"persian\"\n \"bombay\"\n\n\nThe accuracy is given by:\n\nacc = sum(_labels .== preds) / length(preds)\n\n1.0\n\n\nWe can visualize the predictions as follows:\n\nshowsamples(task, collect(zip(images, preds)))"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "contributors.html#local-rendering-instructions",
    "href": "contributors.html#local-rendering-instructions",
    "title": "5  Contributors’ Guide",
    "section": "5.1 Local rendering instructions",
    "text": "5.1 Local rendering instructions\nBy default, the book is rendered automatically through GitHub actions when you merge to main. However, if you want to preview the book locally, you can do so by following these instructions:\n\nClone the repo for this book somewhere on your computer. Navigate using a terminal to the folder containing the repository.\nAdd the Julia kernel to Jupyter. This is currently tested with Julia 1.9, your results may vary with different versions of julia.\n# Load the current environment\nusing Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n\n# Import IJulia\nusing IJulia\n\n# Call a notebook. You can close it once you call this --\n# we only need to run notebook() once for it to build the\n# jupyter kernel for Julia.\nnotebook()\n\n\n\n\n\n\n\nTroubleshooting\n\n\n\nIf you get an error message about jupyter not being found, you may need to build IJulia first. This\n\n\n\nInstall Quarto.\nRender the website from the root of this folder with\nquarto render\nOptionally, if you want to preview the HTML version of the page before you merge it to main, you can run\nquarter preview"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Howard, Jeremy, and Sylvain Gugger. 2020. Deep Learning\nfor Coders with Fastai and PyTorch.\n\"O’Reilly Media, Inc.\".\n\n\nInnes, Mike. 2018. “Flux: Elegant Machine Learning\nwith Julia.” Journal of Open Source\nSoftware 3 (25): 602."
  }
]